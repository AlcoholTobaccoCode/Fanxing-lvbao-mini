<script setup lang="ts">
import { nextTick, ref } from "vue";
import type { PropType } from "vue";
import { isDark } from "@/cool";
import { useUi } from "@/uni_modules/cool-ui";
import { uploadToOss } from "@/utils/aliyun/oss";
import { recognizeOnceFromBuffer } from "@/utils/aliyun/asr";
import type { ToolItem, Tools, ActionItem, Actions, SendData, VoiceResult } from "../types";

import SimpleCard from "@/components/card/simple-card.uvue";
import VoiceRecord from "../voice-record.uvue";
import ActionsPopup from "../actions-popup.uvue";
import RealtimeVoiceInput from "../realtime-voice-input.uvue";

const ui = useUi();

const props = defineProps({
	placeholder: {
		type: String,
		default: () => "在这里输入你的问题"
	},
	loading: {
		type: Boolean,
		default: () => false
	},
	disabled: {
		type: Boolean,
		default: () => false
	},
	/**
	 * inputMode
	 * @default "text"
	 * @description: text -> 文本输入 | voice -> 语音输入
	 */
	inputMode: {
		type: String,
		default: () => "text"
	},
	// 使用的模块，用来分类保存语音 OSS 文件
	useModule: {
		type: String,
		default: () => "ai-chat-voice"
	}, // 顶部工具栏：额外传入的工具项
	tools: {
		type: Array as PropType<Tools>,
		default: () => []
	}
});

const modelValue = defineModel<string>({
	default: ""
});

const emit = defineEmits<{
	(e: "send", value: SendData): void;
	(e: "open-call"): void;
	(e: "input-mode-change", value: string): void;
	// 顶部工具选中变化
	(e: "tool-change", value: Tools): void;
	(e: "tool-toggle", value: ToolItem): void;
}>();

// 输入模式
const inputModeVal = ref(props.inputMode);

//#region 语音录制相关

const voiceRecordRef = ref<any>();
const isShowVoiceRecord = ref<any>(false);

// 按住说话：按下时显示语音浮层并通知开始
const handlePressStart = () => {
	isShowVoiceRecord.value = true;
};

// 松开：关闭浮层并通知结束
const handlePressEnd = () => {
	isShowVoiceRecord.value = false;
};

const handleVoiceRecordFinish = async (result: VoiceResult) => {
	if (!result.tempFilePath) {
		return ui.showToast({ message: "语音丢失，请重试" });
	}
	// 上传 OSS
	const res = await uploadToOss({
		filePath: result.tempFilePath,
		dirPrefix: `${props.useModule}/voice`
	});
	result.onlineUrl = res.url;
	// TODO 录音文件识别
	try {
		uni.showLoading({ title: "识别中..." });
		const text = await recognizeOnceFromBuffer(result.buffer, {
			startParams: {
				format: "mp3",
				sample_rate: 16000
			}
		});
		if (text) {
			result.text = text;
		}
	} catch (err: any) {
		console.error("[chat-input] 语音识别失败", err);
		ui.showToast({ message: err?.message || "语音识别失败" });
	} finally {
		nextTick(() => {
			uni.hideLoading();
		});
	}
	const data: SendData = {
		text: result.text || "",
		mode: "voice",
		voice: {
			...result
		}
	};
	emit("send", data);
	modelValue.value = "";
};

//#endregion

//#region 交互
// 更多功能弹层显隐
const showMoreAction = ref(false);

// 切换输入模式
const handleRecording = () => {
	inputModeVal.value = inputModeVal.value === "text" ? "voice" : "text";
	emit("input-mode-change", inputModeVal.value);
	// 切换到语音模式时，预请求一次录音权限，减少长按时等待
	if (inputModeVal.value === "voice") {
		voiceRecordRef.value?.ensureRecordPermission?.();
	}
};

// 发送
const handleSend = () => {
	if (props.disabled || props.loading) return;
	const val = modelValue.value.trim();

	const data = {
		text: val,
		mode: "text" as const
	};

	if (!val) return;
	emit("send", data);
};

// 确认
const handleConfirm = () => {
	handleSend();
};

// 打开通话组件
const handleOpenCall = () => {
	emit("open-call");
};

// 实时录音状态变化
const handleRealtimeRecordingChange = (isRecording: boolean) => {
	// 可以根据录音状态调整 UI（如隐藏/显示其他按钮）
	console.log("实时录音状态变化:", isRecording);
};

//#endregion
</script>

<template>
	<simple-card class="chat-input-wrapper !py-0" :class="{ 'is-dark': isDark }">
		<!-- 主输入区域 -->
		<view class="chat-main">
			<view :class="['chat-main__inner', modelValue ? '!pl-0' : '']">
				<!-- 默认输入交互区域 -->
				<view class="chat-main__left">
					<view class="chat-main__icon-btn" @tap.stop="handleRecording">
						<cl-icon
							:name="inputModeVal === 'text' ? 'mic-line' : 'keyboard-box-line'"
							:size="48"
							color="currentColor"
						></cl-icon>
					</view>
				</view>
				<view class="chat-main__center">
					<cl-textarea
						v-if="inputModeVal === 'text'"
						class="max-h-[200px]"
						v-model="modelValue"
						clearable
						auto-height
						:border="false"
						:autofocus="true"
						:maxlength="Infinity"
						:showWordLimit="false"
						:disabled="disabled"
						:placeholder="placeholder"
						@confirm="handleConfirm"
					></cl-textarea>

					<view v-else class="chat-main__voice">
						<view
							class="chat-main__voice-hit !h-[40px]"
							@touchstart.stop="handlePressStart"
							@touchend.stop="handlePressEnd"
							@touchcancel.stop="handlePressEnd"
						>
							<cl-button type="primary" size="large" class="chat-main__voice-btn">
								按住 说话
							</cl-button>
						</view>
					</view>
				</view>

				<view class="chat-main__right">
					<!-- 实时语音输入按钮 -->
					<realtime-voice-input
						v-model="modelValue"
						@recording-change="handleRealtimeRecordingChange"
					/>

					<!-- 发送按钮 -->
					<view class="chat-main__icon-btn">
						<cl-icon
							v-if="!modelValue"
							name="arrow-up-circle-line"
							:size="48"
						></cl-icon>
						<cl-icon
							v-else
							name="arrow-up-circle-fill"
							:size="48"
							color="primary"
							@tap.stop="handleConfirm"
						></cl-icon>
					</view>
				</view>
			</view>
		</view>

		<!-- 更多交互弹窗 -->
		<actions-popup
			v-model:is-show="showMoreAction"
			@select-call="handleOpenCall"
		></actions-popup>

		<!-- 语音录制浮层，仅在按住说话时显示 -->
		<voice-record
			v-model:is-show="isShowVoiceRecord"
			ref="voiceRecordRef"
			@finish="handleVoiceRecordFinish"
		></voice-record>
	</simple-card>
</template>

<style scoped lang="scss">
.chat-input-wrapper {
	@apply rounded-none rounded-t-2xl bg-transparent;
	border-width: 0;
}

.chat-intent-row {
	@apply mb-2;
}

.chat-intent-row__inner {
	@apply flex flex-row items-center gap-2 px-1;
}

.chat-intent-chip {
	@apply flex flex-row items-center px-3 py-2 rounded-full bg-white border border-surface-100;
}

.chat-intent-chip__text {
	@apply text-[13px] text-surface-900;
}

.chat-intent-chip--active {
	@apply bg-primary-50 text-primary-700 border-primary-200;
}

.chat-main {
	@apply mt-1;
}

.chat-main__inner {
	@apply flex flex-row items-center bg-white px-3 py-2 shadow-md;
}

.chat-main__left {
	@apply flex flex-row items-center opacity-100 transition-all;
}

.chat-main__center {
	@apply flex-1 mx-2;
}

.chat-main__voice {
	@apply w-full;
}

.chat-main__voice-hit {
	@apply w-full;
}

.chat-main__voice-btn {
	@apply w-full flex flex-row items-center justify-center rounded-full;
}

.chat-main__right {
	@apply flex flex-row items-center gap-3;
}

.chat-main__icon-btn {
	@apply flex items-center justify-center text-surface-700;
}
</style>
